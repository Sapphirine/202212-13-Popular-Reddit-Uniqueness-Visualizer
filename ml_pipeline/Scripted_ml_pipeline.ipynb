{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/alirahman/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:09:46 WARN DAGScheduler: Broadcasting large task binary with size 1473.8 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 778:>                                                        (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:09:50 WARN DAGScheduler: Broadcasting large task binary with size 1383.3 KiB\n",
      "22/12/13 00:09:55 WARN DAGScheduler: Broadcasting large task binary with size 1483.4 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 894:>                                                        (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:10:00 WARN DAGScheduler: Broadcasting large task binary with size 1425.1 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 952:>                                                        (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:10:04 WARN DAGScheduler: Broadcasting large task binary with size 1432.8 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1010:>                                                       (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:10:09 WARN DAGScheduler: Broadcasting large task binary with size 1406.8 KiB\n",
      "22/12/13 00:10:13 WARN DAGScheduler: Broadcasting large task binary with size 1432.1 KiB\n",
      "22/12/13 00:10:18 WARN DAGScheduler: Broadcasting large task binary with size 1397.8 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1184:>                                                       (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:10:22 WARN DAGScheduler: Broadcasting large task binary with size 1355.4 KiB\n",
      "22/12/13 00:10:27 WARN DAGScheduler: Broadcasting large task binary with size 1367.3 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1300:>                                                       (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:10:31 WARN DAGScheduler: Broadcasting large task binary with size 1305.8 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1358:>                                                       (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:10:36 WARN DAGScheduler: Broadcasting large task binary with size 1299.3 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1416:>                                                       (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:10:40 WARN DAGScheduler: Broadcasting large task binary with size 1277.5 KiB\n",
      "22/12/13 00:10:44 WARN DAGScheduler: Broadcasting large task binary with size 1189.0 KiB\n",
      "22/12/13 00:10:48 WARN DAGScheduler: Broadcasting large task binary with size 1314.0 KiB\n",
      "22/12/13 00:10:52 WARN DAGScheduler: Broadcasting large task binary with size 1239.8 KiB\n",
      "22/12/13 00:10:56 WARN DAGScheduler: Broadcasting large task binary with size 1257.5 KiB\n",
      "22/12/13 00:11:00 WARN DAGScheduler: Broadcasting large task binary with size 1177.1 KiB\n",
      "22/12/13 00:11:04 WARN DAGScheduler: Broadcasting large task binary with size 1221.9 KiB\n",
      "22/12/13 00:11:08 WARN DAGScheduler: Broadcasting large task binary with size 1184.2 KiB\n",
      "22/12/13 00:11:12 WARN DAGScheduler: Broadcasting large task binary with size 1114.2 KiB\n",
      "22/12/13 00:11:16 WARN DAGScheduler: Broadcasting large task binary with size 1122.8 KiB\n",
      "22/12/13 00:11:20 WARN DAGScheduler: Broadcasting large task binary with size 1114.2 KiB\n",
      "22/12/13 00:11:23 WARN DAGScheduler: Broadcasting large task binary with size 1095.9 KiB\n",
      "22/12/13 00:11:27 WARN DAGScheduler: Broadcasting large task binary with size 1075.9 KiB\n",
      "22/12/13 00:11:31 WARN DAGScheduler: Broadcasting large task binary with size 1027.1 KiB\n",
      "22/12/13 00:11:35 WARN DAGScheduler: Broadcasting large task binary with size 1056.9 KiB\n",
      "22/12/13 00:11:38 WARN DAGScheduler: Broadcasting large task binary with size 1029.2 KiB\n",
      "22/12/13 00:11:42 WARN DAGScheduler: Broadcasting large task binary with size 1080.2 KiB\n",
      "22/12/13 00:11:46 WARN DAGScheduler: Broadcasting large task binary with size 1048.9 KiB\n",
      "22/12/13 00:11:50 WARN DAGScheduler: Broadcasting large task binary with size 1094.6 KiB\n",
      "22/12/13 00:11:54 WARN DAGScheduler: Broadcasting large task binary with size 1127.2 KiB\n",
      "22/12/13 00:11:58 WARN DAGScheduler: Broadcasting large task binary with size 1103.0 KiB\n",
      "22/12/13 00:12:02 WARN DAGScheduler: Broadcasting large task binary with size 1120.4 KiB\n",
      "22/12/13 00:12:05 WARN DAGScheduler: Broadcasting large task binary with size 1111.3 KiB\n",
      "22/12/13 00:12:09 WARN DAGScheduler: Broadcasting large task binary with size 1102.5 KiB\n",
      "22/12/13 00:12:13 WARN DAGScheduler: Broadcasting large task binary with size 1128.1 KiB\n",
      "22/12/13 00:12:17 WARN DAGScheduler: Broadcasting large task binary with size 1060.8 KiB\n",
      "22/12/13 00:12:21 WARN DAGScheduler: Broadcasting large task binary with size 1142.9 KiB\n",
      "22/12/13 00:12:25 WARN DAGScheduler: Broadcasting large task binary with size 1152.1 KiB\n",
      "22/12/13 00:12:29 WARN DAGScheduler: Broadcasting large task binary with size 1167.1 KiB\n",
      "22/12/13 00:12:33 WARN DAGScheduler: Broadcasting large task binary with size 1152.8 KiB\n",
      "22/12/13 00:12:37 WARN DAGScheduler: Broadcasting large task binary with size 1173.0 KiB\n",
      "22/12/13 00:12:41 WARN DAGScheduler: Broadcasting large task binary with size 1178.4 KiB\n",
      "22/12/13 00:12:45 WARN DAGScheduler: Broadcasting large task binary with size 1170.2 KiB\n",
      "22/12/13 00:12:48 WARN DAGScheduler: Broadcasting large task binary with size 1188.9 KiB\n",
      "22/12/13 00:12:52 WARN DAGScheduler: Broadcasting large task binary with size 1158.7 KiB\n",
      "22/12/13 00:12:56 WARN DAGScheduler: Broadcasting large task binary with size 1152.4 KiB\n",
      "22/12/13 00:13:00 WARN DAGScheduler: Broadcasting large task binary with size 1194.1 KiB\n",
      "22/12/13 00:13:04 WARN DAGScheduler: Broadcasting large task binary with size 1110.9 KiB\n",
      "22/12/13 00:13:08 WARN DAGScheduler: Broadcasting large task binary with size 1190.2 KiB\n",
      "22/12/13 00:13:12 WARN DAGScheduler: Broadcasting large task binary with size 1173.5 KiB\n",
      "22/12/13 00:13:16 WARN DAGScheduler: Broadcasting large task binary with size 1203.0 KiB\n",
      "22/12/13 00:13:20 WARN DAGScheduler: Broadcasting large task binary with size 1192.8 KiB\n",
      "22/12/13 00:13:24 WARN DAGScheduler: Broadcasting large task binary with size 1201.9 KiB\n",
      "22/12/13 00:13:28 WARN DAGScheduler: Broadcasting large task binary with size 1248.4 KiB\n",
      "22/12/13 00:13:32 WARN DAGScheduler: Broadcasting large task binary with size 1244.7 KiB\n",
      "22/12/13 00:13:36 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 4084:>                                                       (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:13:40 WARN DAGScheduler: Broadcasting large task binary with size 1219.8 KiB\n",
      "22/12/13 00:13:44 WARN DAGScheduler: Broadcasting large task binary with size 1230.0 KiB\n",
      "22/12/13 00:13:49 WARN DAGScheduler: Broadcasting large task binary with size 1280.5 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 4258:>                                                       (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:13:53 WARN DAGScheduler: Broadcasting large task binary with size 1225.5 KiB\n",
      "22/12/13 00:13:57 WARN DAGScheduler: Broadcasting large task binary with size 1324.2 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 4374:>                                                       (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:14:01 WARN DAGScheduler: Broadcasting large task binary with size 1265.0 KiB\n",
      "22/12/13 00:14:06 WARN DAGScheduler: Broadcasting large task binary with size 1297.6 KiB\n",
      "22/12/13 00:14:10 WARN DAGScheduler: Broadcasting large task binary with size 1262.0 KiB\n",
      "22/12/13 00:14:14 WARN DAGScheduler: Broadcasting large task binary with size 1308.9 KiB\n",
      "22/12/13 00:14:18 WARN DAGScheduler: Broadcasting large task binary with size 1336.8 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 4664:>                                                       (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:14:22 WARN DAGScheduler: Broadcasting large task binary with size 1322.3 KiB\n",
      "22/12/13 00:14:26 WARN DAGScheduler: Broadcasting large task binary with size 1310.2 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 4780:>                                                       (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:14:30 WARN DAGScheduler: Broadcasting large task binary with size 1292.9 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 4838:>                                                       (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:14:35 WARN DAGScheduler: Broadcasting large task binary with size 1336.8 KiB\n",
      "22/12/13 00:14:39 WARN DAGScheduler: Broadcasting large task binary with size 1336.8 KiB\n",
      "22/12/13 00:14:43 WARN DAGScheduler: Broadcasting large task binary with size 1308.7 KiB\n",
      "22/12/13 00:14:47 WARN DAGScheduler: Broadcasting large task binary with size 1336.2 KiB\n",
      "22/12/13 00:14:51 WARN DAGScheduler: Broadcasting large task binary with size 1352.6 KiB\n",
      "22/12/13 00:14:55 WARN DAGScheduler: Broadcasting large task binary with size 1334.8 KiB\n",
      "22/12/13 00:14:59 WARN DAGScheduler: Broadcasting large task binary with size 1304.6 KiB\n",
      "22/12/13 00:15:03 WARN DAGScheduler: Broadcasting large task binary with size 1296.3 KiB\n",
      "22/12/13 00:15:07 WARN DAGScheduler: Broadcasting large task binary with size 1325.2 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 5360:>                                                       (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:15:11 WARN DAGScheduler: Broadcasting large task binary with size 1290.8 KiB\n",
      "22/12/13 00:15:15 WARN DAGScheduler: Broadcasting large task binary with size 1281.8 KiB\n",
      "22/12/13 00:15:19 WARN DAGScheduler: Broadcasting large task binary with size 1245.2 KiB\n",
      "22/12/13 00:15:23 WARN DAGScheduler: Broadcasting large task binary with size 1270.4 KiB\n",
      "22/12/13 00:15:27 WARN DAGScheduler: Broadcasting large task binary with size 1279.5 KiB\n",
      "22/12/13 00:15:31 WARN DAGScheduler: Broadcasting large task binary with size 1202.1 KiB\n",
      "22/12/13 00:15:35 WARN DAGScheduler: Broadcasting large task binary with size 1298.8 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 5766:>                                                       (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:15:39 WARN DAGScheduler: Broadcasting large task binary with size 1257.6 KiB\n",
      "22/12/13 00:15:43 WARN DAGScheduler: Broadcasting large task binary with size 1290.0 KiB\n",
      "22/12/13 00:15:47 WARN DAGScheduler: Broadcasting large task binary with size 1262.7 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 5940:>                                                       (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:15:52 WARN DAGScheduler: Broadcasting large task binary with size 1307.0 KiB\n",
      "22/12/13 00:15:56 WARN DAGScheduler: Broadcasting large task binary with size 1285.8 KiB\n",
      "22/12/13 00:16:00 WARN DAGScheduler: Broadcasting large task binary with size 1278.2 KiB\n",
      "22/12/13 00:16:04 WARN DAGScheduler: Broadcasting large task binary with size 1311.9 KiB\n",
      "22/12/13 00:16:08 WARN DAGScheduler: Broadcasting large task binary with size 1259.8 KiB\n",
      "22/12/13 00:16:12 WARN DAGScheduler: Broadcasting large task binary with size 1289.6 KiB\n",
      "22/12/13 00:16:16 WARN DAGScheduler: Broadcasting large task binary with size 1325.7 KiB\n",
      "22/12/13 00:16:19 WARN DAGScheduler: Broadcasting large task binary with size 1207.2 KiB\n",
      "22/12/13 00:16:23 WARN DAGScheduler: Broadcasting large task binary with size 1266.9 KiB\n",
      "22/12/13 00:16:27 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n",
      "22/12/13 00:16:31 WARN DAGScheduler: Broadcasting large task binary with size 1260.7 KiB\n",
      "22/12/13 00:16:35 WARN DAGScheduler: Broadcasting large task binary with size 1247.0 KiB\n",
      "22/12/13 00:16:39 WARN DAGScheduler: Broadcasting large task binary with size 1265.9 KiB\n",
      "22/12/13 00:16:43 WARN DAGScheduler: Broadcasting large task binary with size 1250.3 KiB\n",
      "22/12/13 00:16:47 WARN DAGScheduler: Broadcasting large task binary with size 1216.2 KiB\n",
      "22/12/13 00:16:51 WARN DAGScheduler: Broadcasting large task binary with size 1249.2 KiB\n",
      "22/12/13 00:16:54 WARN DAGScheduler: Broadcasting large task binary with size 1205.5 KiB\n",
      "22/12/13 00:16:58 WARN DAGScheduler: Broadcasting large task binary with size 1213.5 KiB\n",
      "22/12/13 00:17:02 WARN DAGScheduler: Broadcasting large task binary with size 1188.0 KiB\n",
      "22/12/13 00:17:06 WARN DAGScheduler: Broadcasting large task binary with size 1116.1 KiB\n",
      "22/12/13 00:17:10 WARN DAGScheduler: Broadcasting large task binary with size 1178.7 KiB\n",
      "22/12/13 00:17:13 WARN DAGScheduler: Broadcasting large task binary with size 1138.5 KiB\n",
      "22/12/13 00:17:17 WARN DAGScheduler: Broadcasting large task binary with size 1081.5 KiB\n",
      "22/12/13 00:17:21 WARN DAGScheduler: Broadcasting large task binary with size 1087.4 KiB\n",
      "22/12/13 00:17:24 WARN DAGScheduler: Broadcasting large task binary with size 1090.3 KiB\n",
      "22/12/13 00:17:28 WARN DAGScheduler: Broadcasting large task binary with size 1084.7 KiB\n",
      "22/12/13 00:17:31 WARN DAGScheduler: Broadcasting large task binary with size 1040.8 KiB\n",
      "22/12/13 00:17:35 WARN DAGScheduler: Broadcasting large task binary with size 1092.4 KiB\n",
      "22/12/13 00:17:38 WARN DAGScheduler: Broadcasting large task binary with size 1080.9 KiB\n",
      "22/12/13 00:17:42 WARN DAGScheduler: Broadcasting large task binary with size 1081.4 KiB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "\n",
    "# https://stackoverflow.com/questions/51390676/how-to-visualize-pyspark-mls-lda-or-other-clustering\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from pyspark import SparkConf, SparkContext,SQLContext\n",
    "from pyspark.sql import SparkSession, functions\n",
    "from pyspark.ml.feature import Word2Vec,CountVectorizer,Tokenizer, StopWordsRemover\n",
    "from pyspark.ml.clustering import LDA, LDAModel\n",
    "from pyspark.sql.functions import col, udf, countDistinct, regexp_replace\n",
    "from pyspark.sql.types import IntegerType,ArrayType,StringType\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import lit\n",
    "import csv\n",
    "\n",
    "def ith_(v, i):\n",
    "    try:\n",
    "        return float(v[i])\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "spark = SparkSession \\\n",
    ".builder \\\n",
    ".appName(\"Python Spark SQL basic example\") \\\n",
    ".config(\"spark.some.config.option\", \"some-value\") \\\n",
    ".getOrCreate()\n",
    "\n",
    "months = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "#months = [\"November\"]\n",
    "years = [\"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\"]\n",
    "#years = [\"2010\"]\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        csv_path = \"/\" + year + \"/\" + month + \".csv\"\n",
    "        json_path = \"/\" + year + \"/\" + month + \".json\"\n",
    "        data_path = \"../data\" + csv_path # Data path for csv file\n",
    "        spark_df = spark.read.csv(data_path, inferSchema = True, header=True) # checking the csv file\n",
    "        spark_df = spark_df.withColumn('Title', regexp_replace('Title', '\"', ''))\n",
    "        spark_df = spark_df.withColumn('Title', regexp_replace('Title', '-', ''))\n",
    "        spark_df = spark_df.withColumn('Title', regexp_replace('Title', '\\.', ''))\n",
    "        spark_df = spark_df.withColumn('Title', regexp_replace('Title', ',', ''))\n",
    "        spark_df = spark_df.withColumn('Title', regexp_replace('Title', '\\?', ''))\n",
    "        spark_df = spark_df.withColumn('Title', regexp_replace('Title', '\\!', ''))\n",
    "        spark_df = spark_df.withColumn('Title', regexp_replace('Title', '\\/', ''))\n",
    "        spark_df = spark_df.withColumn('Title', regexp_replace('Title', '\\\\\\\\', ''))\n",
    "        spark_df = spark_df.withColumn('Title', regexp_replace('Title', \"'\", ''))\n",
    "        spark_df = spark_df.withColumn('Title', regexp_replace('Title', ':', ''))\n",
    "        # Topic Modelling on Title (Potentially do it on description if possible)\n",
    "        node = \"Title\"\n",
    "        # Get title data, filter out empty nodes\n",
    "        title_data = spark_df.select(node).filter(functions.col(node).isNotNull())\n",
    "\n",
    "        df2 = spark_df.select(countDistinct(\"Subreddit\"))\n",
    "        topic_num = df2.first()[0]\n",
    "\n",
    "        tokenizer = Tokenizer(inputCol=\"Title\", outputCol=\"words\")\n",
    "        tokenized = tokenizer.transform(spark_df)\n",
    "        remover = StopWordsRemover(stopWords=stopwords.words('english'), inputCol=\"words\", outputCol=\"filtered\")\n",
    "        result = remover.transform(tokenized)\n",
    "        # result.select(\"filtered\").show()\n",
    "\n",
    "        cv = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\")\n",
    "        cvModel = cv.fit(result)\n",
    "        cvResult = cvModel.transform(result)\n",
    "\n",
    "        lda = LDA(maxIter=20, k = 10)\n",
    "        ldaModel = lda.fit(cvResult)\n",
    "        transformed = ldaModel.transform(cvResult).select(\"topicDistribution\")\n",
    "        #transformed.show(truncate=False)\n",
    "\n",
    "        vocab = cvModel.vocabulary\n",
    "        topics = ldaModel.describeTopics()\n",
    "        topics_rdd = topics.rdd\n",
    "\n",
    "        topics_words = topics_rdd\\\n",
    "               .map(lambda row: row['termIndices'])\\\n",
    "               .map(lambda idx_list: [vocab[idx] for idx in idx_list])\\\n",
    "               .collect()\n",
    "        topic_weights = topics_rdd\\\n",
    "               .map(lambda row: row['termWeights'])\\\n",
    "               .collect()\n",
    "\n",
    "        file_path = \"../processed_data\" + csv_path\n",
    "        if not os.path.exists(\"../processed_data/\" + year):\n",
    "            os.makedirs(\"../processed_data/\" + year)\n",
    "        with open(file_path, 'w') as file:\n",
    "            header = [\"term\", \"probability\", \"topic\"]\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(header)\n",
    "            for idx, topic in enumerate(topics_words):\n",
    "                i = 0\n",
    "                for word in topic:\n",
    "                    data = [word, topic_weights[idx][i], idx]\n",
    "                    writer.writerow(data)\n",
    "                    i = i+1\n",
    "\n",
    "        json_df = pd.read_csv(file_path)\n",
    "        json_df.to_json(\"../processed_data\" + json_path, orient = \"table\")\n",
    "        \n",
    "        dist = ldaModel.transform(cvResult)\n",
    "\n",
    "        ith = udf(ith_, DoubleType())\n",
    "        df = dist.select([\"Title\"] + [ith(\"topicDistribution\", lit(i)).alias('topic_'+str(i)) for i in range(10)] )\n",
    "\n",
    "        df_p = dist.select('topicDistribution').toPandas()\n",
    "        df_p1 = df_p.topicDistribution.apply(lambda x:np.array(x))\n",
    "        df_p2 = pd.DataFrame(df_p1.tolist()).apply(lambda x:x.argmax(),axis=1)\n",
    "        df_p3 = df_p2.reset_index()\n",
    "        df_p3.columns = ['doc','topic']\n",
    "        df2_p = dist.select('Title').toPandas()\n",
    "        #print(df_p3)\n",
    "        final_df = pd.concat([df2_p, df_p3], axis=1)\n",
    "        topic_path = \"../document_topics\" + csv_path\n",
    "        if not os.path.exists(\"../document_topics/\" + year):\n",
    "            os.makedirs(\"../document_topics/\" + year)\n",
    "        final_df.to_csv(topic_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
