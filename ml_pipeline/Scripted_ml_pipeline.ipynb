{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/alirahman/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/12 01:18:04 WARN DAGScheduler: Broadcasting large task binary with size 1930.4 KiB\n",
      "22/12/12 01:18:08 WARN DAGScheduler: Broadcasting large task binary with size 1783.6 KiB\n",
      "22/12/12 01:18:12 WARN DAGScheduler: Broadcasting large task binary with size 1930.8 KiB\n",
      "22/12/12 01:18:16 WARN DAGScheduler: Broadcasting large task binary with size 1839.5 KiB\n",
      "22/12/12 01:18:20 WARN DAGScheduler: Broadcasting large task binary with size 1868.5 KiB\n",
      "22/12/12 01:18:24 WARN DAGScheduler: Broadcasting large task binary with size 1826.0 KiB\n",
      "22/12/12 01:18:27 WARN DAGScheduler: Broadcasting large task binary with size 1844.7 KiB\n",
      "22/12/12 01:18:31 WARN DAGScheduler: Broadcasting large task binary with size 1815.6 KiB\n",
      "22/12/12 01:18:35 WARN DAGScheduler: Broadcasting large task binary with size 1776.5 KiB\n",
      "22/12/12 01:18:39 WARN DAGScheduler: Broadcasting large task binary with size 1795.8 KiB\n",
      "22/12/12 01:18:43 WARN DAGScheduler: Broadcasting large task binary with size 1713.9 KiB\n",
      "22/12/12 01:18:47 WARN DAGScheduler: Broadcasting large task binary with size 1701.6 KiB\n",
      "22/12/12 01:18:51 WARN DAGScheduler: Broadcasting large task binary with size 1676.3 KiB\n",
      "22/12/12 01:18:54 WARN DAGScheduler: Broadcasting large task binary with size 1556.1 KiB\n",
      "22/12/12 01:18:58 WARN DAGScheduler: Broadcasting large task binary with size 1721.4 KiB\n",
      "22/12/12 01:19:02 WARN DAGScheduler: Broadcasting large task binary with size 1624.8 KiB\n",
      "22/12/12 01:19:06 WARN DAGScheduler: Broadcasting large task binary with size 1646.7 KiB\n",
      "22/12/12 01:19:09 WARN DAGScheduler: Broadcasting large task binary with size 1538.3 KiB\n",
      "22/12/12 01:19:13 WARN DAGScheduler: Broadcasting large task binary with size 1602.8 KiB\n",
      "22/12/12 01:19:16 WARN DAGScheduler: Broadcasting large task binary with size 1552.0 KiB\n",
      "22/12/12 01:19:20 WARN DAGScheduler: Broadcasting large task binary with size 1453.0 KiB\n",
      "22/12/12 01:19:24 WARN DAGScheduler: Broadcasting large task binary with size 1474.2 KiB\n",
      "22/12/12 01:19:27 WARN DAGScheduler: Broadcasting large task binary with size 1456.1 KiB\n",
      "22/12/12 01:19:31 WARN DAGScheduler: Broadcasting large task binary with size 1435.5 KiB\n",
      "22/12/12 01:19:34 WARN DAGScheduler: Broadcasting large task binary with size 1407.0 KiB\n",
      "22/12/12 01:19:38 WARN DAGScheduler: Broadcasting large task binary with size 1325.2 KiB\n",
      "22/12/12 01:19:41 WARN DAGScheduler: Broadcasting large task binary with size 1365.8 KiB\n",
      "22/12/12 01:19:44 WARN DAGScheduler: Broadcasting large task binary with size 1329.9 KiB\n",
      "22/12/12 01:19:48 WARN DAGScheduler: Broadcasting large task binary with size 1407.7 KiB\n",
      "22/12/12 01:19:51 WARN DAGScheduler: Broadcasting large task binary with size 1364.9 KiB\n",
      "22/12/12 01:19:55 WARN DAGScheduler: Broadcasting large task binary with size 1426.6 KiB\n",
      "22/12/12 01:19:58 WARN DAGScheduler: Broadcasting large task binary with size 1469.4 KiB\n",
      "22/12/12 01:20:02 WARN DAGScheduler: Broadcasting large task binary with size 1437.0 KiB\n",
      "22/12/12 01:20:05 WARN DAGScheduler: Broadcasting large task binary with size 1460.6 KiB\n",
      "22/12/12 01:20:09 WARN DAGScheduler: Broadcasting large task binary with size 1440.7 KiB\n",
      "22/12/12 01:20:12 WARN DAGScheduler: Broadcasting large task binary with size 1431.2 KiB\n",
      "22/12/12 01:20:16 WARN DAGScheduler: Broadcasting large task binary with size 1459.8 KiB\n",
      "22/12/12 01:20:19 WARN DAGScheduler: Broadcasting large task binary with size 1357.7 KiB\n",
      "22/12/12 01:20:22 WARN DAGScheduler: Broadcasting large task binary with size 1476.6 KiB\n",
      "22/12/12 01:20:26 WARN DAGScheduler: Broadcasting large task binary with size 1479.5 KiB\n",
      "22/12/12 01:20:30 WARN DAGScheduler: Broadcasting large task binary with size 1511.8 KiB\n",
      "22/12/12 01:20:33 WARN DAGScheduler: Broadcasting large task binary with size 1497.0 KiB\n",
      "22/12/12 01:20:37 WARN DAGScheduler: Broadcasting large task binary with size 1516.6 KiB\n",
      "22/12/12 01:20:41 WARN DAGScheduler: Broadcasting large task binary with size 1523.7 KiB\n",
      "22/12/12 01:20:44 WARN DAGScheduler: Broadcasting large task binary with size 1508.9 KiB\n",
      "22/12/12 01:20:48 WARN DAGScheduler: Broadcasting large task binary with size 1524.4 KiB\n",
      "22/12/12 01:20:51 WARN DAGScheduler: Broadcasting large task binary with size 1478.0 KiB\n",
      "22/12/12 01:20:55 WARN DAGScheduler: Broadcasting large task binary with size 1478.0 KiB\n",
      "22/12/12 01:20:59 WARN DAGScheduler: Broadcasting large task binary with size 1529.2 KiB\n",
      "22/12/12 01:21:02 WARN DAGScheduler: Broadcasting large task binary with size 1404.5 KiB\n",
      "22/12/12 01:21:06 WARN DAGScheduler: Broadcasting large task binary with size 1520.9 KiB\n",
      "22/12/12 01:21:09 WARN DAGScheduler: Broadcasting large task binary with size 1492.2 KiB\n",
      "22/12/12 01:21:13 WARN DAGScheduler: Broadcasting large task binary with size 1539.4 KiB\n",
      "22/12/12 01:21:16 WARN DAGScheduler: Broadcasting large task binary with size 1527.3 KiB\n",
      "22/12/12 01:21:20 WARN DAGScheduler: Broadcasting large task binary with size 1527.5 KiB\n",
      "22/12/12 01:21:23 WARN DAGScheduler: Broadcasting large task binary with size 1590.4 KiB\n",
      "22/12/12 01:21:27 WARN DAGScheduler: Broadcasting large task binary with size 1581.8 KiB\n",
      "22/12/12 01:21:31 WARN DAGScheduler: Broadcasting large task binary with size 1596.2 KiB\n",
      "22/12/12 01:21:34 WARN DAGScheduler: Broadcasting large task binary with size 1552.9 KiB\n",
      "22/12/12 01:21:38 WARN DAGScheduler: Broadcasting large task binary with size 1562.3 KiB\n",
      "22/12/12 01:21:42 WARN DAGScheduler: Broadcasting large task binary with size 1623.0 KiB\n",
      "22/12/12 01:21:45 WARN DAGScheduler: Broadcasting large task binary with size 1537.7 KiB\n",
      "22/12/12 01:21:49 WARN DAGScheduler: Broadcasting large task binary with size 1678.8 KiB\n",
      "22/12/12 01:21:53 WARN DAGScheduler: Broadcasting large task binary with size 1602.9 KiB\n",
      "22/12/12 01:21:57 WARN DAGScheduler: Broadcasting large task binary with size 1650.6 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9510:>                                                       (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/12 01:22:01 WARN DAGScheduler: Broadcasting large task binary with size 1595.6 KiB\n",
      "22/12/12 01:22:04 WARN DAGScheduler: Broadcasting large task binary with size 1653.2 KiB\n",
      "22/12/12 01:22:08 WARN DAGScheduler: Broadcasting large task binary with size 1677.6 KiB\n",
      "22/12/12 01:22:12 WARN DAGScheduler: Broadcasting large task binary with size 1659.2 KiB\n",
      "22/12/12 01:22:16 WARN DAGScheduler: Broadcasting large task binary with size 1644.8 KiB\n",
      "22/12/12 01:22:19 WARN DAGScheduler: Broadcasting large task binary with size 1619.6 KiB\n",
      "22/12/12 01:22:23 WARN DAGScheduler: Broadcasting large task binary with size 1684.6 KiB\n",
      "22/12/12 01:22:27 WARN DAGScheduler: Broadcasting large task binary with size 1680.6 KiB\n",
      "22/12/12 01:22:31 WARN DAGScheduler: Broadcasting large task binary with size 1641.4 KiB\n",
      "22/12/12 01:22:34 WARN DAGScheduler: Broadcasting large task binary with size 1684.7 KiB\n",
      "22/12/12 01:22:38 WARN DAGScheduler: Broadcasting large task binary with size 1692.8 KiB\n",
      "22/12/12 01:22:42 WARN DAGScheduler: Broadcasting large task binary with size 1672.2 KiB\n",
      "22/12/12 01:22:46 WARN DAGScheduler: Broadcasting large task binary with size 1623.5 KiB\n",
      "22/12/12 01:22:50 WARN DAGScheduler: Broadcasting large task binary with size 1629.4 KiB\n",
      "22/12/12 01:22:54 WARN DAGScheduler: Broadcasting large task binary with size 1656.8 KiB\n",
      "22/12/12 01:22:57 WARN DAGScheduler: Broadcasting large task binary with size 1602.7 KiB\n",
      "22/12/12 01:23:01 WARN DAGScheduler: Broadcasting large task binary with size 1586.0 KiB\n",
      "22/12/12 01:23:04 WARN DAGScheduler: Broadcasting large task binary with size 1543.1 KiB\n",
      "22/12/12 01:23:08 WARN DAGScheduler: Broadcasting large task binary with size 1574.4 KiB\n",
      "22/12/12 01:23:12 WARN DAGScheduler: Broadcasting large task binary with size 1601.2 KiB\n",
      "22/12/12 01:23:15 WARN DAGScheduler: Broadcasting large task binary with size 1488.8 KiB\n",
      "22/12/12 01:23:19 WARN DAGScheduler: Broadcasting large task binary with size 1614.2 KiB\n",
      "22/12/12 01:23:23 WARN DAGScheduler: Broadcasting large task binary with size 1558.8 KiB\n",
      "22/12/12 01:23:26 WARN DAGScheduler: Broadcasting large task binary with size 1597.7 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 10902:>                                                      (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/12 01:23:30 WARN DAGScheduler: Broadcasting large task binary with size 1565.9 KiB\n",
      "22/12/12 01:23:34 WARN DAGScheduler: Broadcasting large task binary with size 1619.2 KiB\n",
      "22/12/12 01:23:37 WARN DAGScheduler: Broadcasting large task binary with size 1584.3 KiB\n",
      "22/12/12 01:23:41 WARN DAGScheduler: Broadcasting large task binary with size 1574.9 KiB\n",
      "22/12/12 01:23:45 WARN DAGScheduler: Broadcasting large task binary with size 1608.3 KiB\n",
      "22/12/12 01:23:48 WARN DAGScheduler: Broadcasting large task binary with size 1558.4 KiB\n",
      "22/12/12 01:23:52 WARN DAGScheduler: Broadcasting large task binary with size 1596.1 KiB\n",
      "22/12/12 01:23:56 WARN DAGScheduler: Broadcasting large task binary with size 1635.2 KiB\n",
      "22/12/12 01:23:59 WARN DAGScheduler: Broadcasting large task binary with size 1475.8 KiB\n",
      "22/12/12 01:24:03 WARN DAGScheduler: Broadcasting large task binary with size 1564.4 KiB\n",
      "22/12/12 01:24:06 WARN DAGScheduler: Broadcasting large task binary with size 1541.1 KiB\n",
      "22/12/12 01:24:10 WARN DAGScheduler: Broadcasting large task binary with size 1557.6 KiB\n",
      "22/12/12 01:24:14 WARN DAGScheduler: Broadcasting large task binary with size 1529.2 KiB\n",
      "22/12/12 01:24:17 WARN DAGScheduler: Broadcasting large task binary with size 1564.5 KiB\n",
      "22/12/12 01:24:21 WARN DAGScheduler: Broadcasting large task binary with size 1542.4 KiB\n",
      "22/12/12 01:24:24 WARN DAGScheduler: Broadcasting large task binary with size 1494.4 KiB\n",
      "22/12/12 01:24:28 WARN DAGScheduler: Broadcasting large task binary with size 1533.8 KiB\n",
      "22/12/12 01:24:31 WARN DAGScheduler: Broadcasting large task binary with size 1487.9 KiB\n",
      "22/12/12 01:24:35 WARN DAGScheduler: Broadcasting large task binary with size 1500.9 KiB\n",
      "22/12/12 01:24:39 WARN DAGScheduler: Broadcasting large task binary with size 1465.7 KiB\n",
      "22/12/12 01:24:42 WARN DAGScheduler: Broadcasting large task binary with size 1355.4 KiB\n",
      "22/12/12 01:24:45 WARN DAGScheduler: Broadcasting large task binary with size 1453.2 KiB\n",
      "22/12/12 01:24:49 WARN DAGScheduler: Broadcasting large task binary with size 1403.7 KiB\n",
      "22/12/12 01:24:52 WARN DAGScheduler: Broadcasting large task binary with size 1315.9 KiB\n",
      "22/12/12 01:24:55 WARN DAGScheduler: Broadcasting large task binary with size 1321.8 KiB\n",
      "22/12/12 01:24:59 WARN DAGScheduler: Broadcasting large task binary with size 1328.7 KiB\n",
      "22/12/12 01:25:02 WARN DAGScheduler: Broadcasting large task binary with size 1319.8 KiB\n",
      "22/12/12 01:25:05 WARN DAGScheduler: Broadcasting large task binary with size 1258.4 KiB\n",
      "22/12/12 01:25:09 WARN DAGScheduler: Broadcasting large task binary with size 1324.8 KiB\n",
      "22/12/12 01:25:12 WARN DAGScheduler: Broadcasting large task binary with size 1305.2 KiB\n",
      "22/12/12 01:25:15 WARN DAGScheduler: Broadcasting large task binary with size 1309.5 KiB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "\n",
    "# https://stackoverflow.com/questions/51390676/how-to-visualize-pyspark-mls-lda-or-other-clustering\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from pyspark import SparkConf, SparkContext,SQLContext\n",
    "from pyspark.sql import SparkSession, functions\n",
    "from pyspark.ml.feature import Word2Vec,CountVectorizer,Tokenizer, StopWordsRemover\n",
    "from pyspark.ml.clustering import LDA, LDAModel\n",
    "from pyspark.sql.functions import col, udf, countDistinct, regexp_replace\n",
    "from pyspark.sql.types import IntegerType,ArrayType,StringType\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import lit\n",
    "import csv\n",
    "\n",
    "def ith_(v, i):\n",
    "    try:\n",
    "        return float(v[i])\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "spark = SparkSession \\\n",
    ".builder \\\n",
    ".appName(\"Python Spark SQL basic example\") \\\n",
    ".config(\"spark.some.config.option\", \"some-value\") \\\n",
    ".getOrCreate()\n",
    "\n",
    "months = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "month = \"November\"\n",
    "years = [\"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\"]\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        csv_path = \"/\" + year + \"/\" + month + \".csv\"\n",
    "        json_path = \"/\" + year + \"/\" + month + \".json\"\n",
    "        data_path = \"../data\" + csv_path # Data path for csv file\n",
    "        spark_df = spark.read.csv(data_path, inferSchema = True, header=True) # checking the csv file\n",
    "        spark_df = spark_df.withColumn('Title', regexp_replace('Title', '\"', ''))\n",
    "        # Topic Modelling on Title (Potentially do it on description if possible)\n",
    "        node = \"Title\"\n",
    "        # Get title data, filter out empty nodes\n",
    "        title_data = spark_df.select(node).filter(functions.col(node).isNotNull())\n",
    "\n",
    "        df2 = spark_df.select(countDistinct(\"Subreddit\"))\n",
    "        topic_num = df2.first()[0]\n",
    "\n",
    "        tokenizer = Tokenizer(inputCol=\"Title\", outputCol=\"words\")\n",
    "        tokenized = tokenizer.transform(spark_df)\n",
    "        remover = StopWordsRemover(stopWords=stopwords.words('english'), inputCol=\"words\", outputCol=\"filtered\")\n",
    "        result = remover.transform(tokenized)\n",
    "        # result.select(\"filtered\").show()\n",
    "\n",
    "        cv = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\")\n",
    "        cvModel = cv.fit(result)\n",
    "        cvResult = cvModel.transform(result)\n",
    "\n",
    "        lda = LDA(maxIter=20, k = 10)\n",
    "        ldaModel = lda.fit(cvResult)\n",
    "        transformed = ldaModel.transform(cvResult).select(\"topicDistribution\")\n",
    "        #transformed.show(truncate=False)\n",
    "\n",
    "        vocab = cvModel.vocabulary\n",
    "        topics = ldaModel.describeTopics()\n",
    "        topics_rdd = topics.rdd\n",
    "\n",
    "        topics_words = topics_rdd\\\n",
    "               .map(lambda row: row['termIndices'])\\\n",
    "               .map(lambda idx_list: [vocab[idx] for idx in idx_list])\\\n",
    "               .collect()\n",
    "        topic_weights = topics_rdd\\\n",
    "               .map(lambda row: row['termWeights'])\\\n",
    "               .collect()\n",
    "\n",
    "        file_path = \"../processed_data\" + csv_path\n",
    "        if not os.path.exists(\"../processed_data/\" + year):\n",
    "            os.makedirs(\"../processed_data/\" + year)\n",
    "        with open(file_path, 'w') as file:\n",
    "            header = [\"term\", \"probability\", \"topic\"]\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(header)\n",
    "            for idx, topic in enumerate(topics_words):\n",
    "                i = 0\n",
    "                for word in topic:\n",
    "                    data = [word, topic_weights[idx][i], idx]\n",
    "                    writer.writerow(data)\n",
    "                    i = i+1\n",
    "\n",
    "        json_df = pd.read_csv(file_path)\n",
    "        json_df.to_json(\"../processed_data\" + json_path, orient = \"table\")\n",
    "        \n",
    "        dist = ldaModel.transform(cvResult)\n",
    "\n",
    "        ith = udf(ith_, DoubleType())\n",
    "        df = dist.select([\"Title\"] + [ith(\"topicDistribution\", lit(i)).alias('topic_'+str(i)) for i in range(10)] )\n",
    "\n",
    "        df_p = dist.select('topicDistribution').toPandas()\n",
    "        df_p1 = df_p.topicDistribution.apply(lambda x:np.array(x))\n",
    "        df_p2 = pd.DataFrame(df_p1.tolist()).apply(lambda x:x.argmax(),axis=1)\n",
    "        df_p3 = df_p2.reset_index()\n",
    "        df_p3.columns = ['doc','topic']\n",
    "        df2_p = dist.select('Title').toPandas()\n",
    "        #print(df_p3)\n",
    "        final_df = pd.concat([df2_p, df_p3], axis=1)\n",
    "        topic_path = \"../document_topics\" + csv_path\n",
    "        if not os.path.exists(\"../document_topics/\" + year):\n",
    "            os.makedirs(\"../document_topics/\" + year)\n",
    "        final_df.to_csv(topic_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
