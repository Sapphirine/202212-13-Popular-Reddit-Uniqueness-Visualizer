{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/alirahman/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:40:08 WARN DAGScheduler: Broadcasting large task binary with size 1448.6 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8100:>                                                       (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:40:12 WARN DAGScheduler: Broadcasting large task binary with size 1358.2 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8158:>                                                       (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:40:16 WARN DAGScheduler: Broadcasting large task binary with size 1458.2 KiB\n",
      "22/12/13 00:40:20 WARN DAGScheduler: Broadcasting large task binary with size 1400.0 KiB\n",
      "22/12/13 00:40:25 WARN DAGScheduler: Broadcasting large task binary with size 1407.6 KiB\n",
      "22/12/13 00:40:29 WARN DAGScheduler: Broadcasting large task binary with size 1381.7 KiB\n",
      "22/12/13 00:40:33 WARN DAGScheduler: Broadcasting large task binary with size 1406.9 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8448:>                                                       (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:40:37 WARN DAGScheduler: Broadcasting large task binary with size 1372.7 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8506:>                                                       (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:40:41 WARN DAGScheduler: Broadcasting large task binary with size 1330.3 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8564:>                                                       (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:40:45 WARN DAGScheduler: Broadcasting large task binary with size 1342.2 KiB\n",
      "22/12/13 00:40:49 WARN DAGScheduler: Broadcasting large task binary with size 1280.6 KiB\n",
      "22/12/13 00:40:53 WARN DAGScheduler: Broadcasting large task binary with size 1274.1 KiB\n",
      "22/12/13 00:40:57 WARN DAGScheduler: Broadcasting large task binary with size 1252.3 KiB\n",
      "22/12/13 00:41:01 WARN DAGScheduler: Broadcasting large task binary with size 1163.9 KiB\n",
      "22/12/13 00:41:05 WARN DAGScheduler: Broadcasting large task binary with size 1288.8 KiB\n",
      "22/12/13 00:41:09 WARN DAGScheduler: Broadcasting large task binary with size 1214.6 KiB\n",
      "22/12/13 00:41:12 WARN DAGScheduler: Broadcasting large task binary with size 1232.3 KiB\n",
      "22/12/13 00:41:16 WARN DAGScheduler: Broadcasting large task binary with size 1152.0 KiB\n",
      "22/12/13 00:41:20 WARN DAGScheduler: Broadcasting large task binary with size 1196.7 KiB\n",
      "22/12/13 00:41:23 WARN DAGScheduler: Broadcasting large task binary with size 1159.0 KiB\n",
      "22/12/13 00:41:27 WARN DAGScheduler: Broadcasting large task binary with size 1089.1 KiB\n",
      "22/12/13 00:41:31 WARN DAGScheduler: Broadcasting large task binary with size 1097.6 KiB\n",
      "22/12/13 00:41:34 WARN DAGScheduler: Broadcasting large task binary with size 1089.0 KiB\n",
      "22/12/13 00:41:38 WARN DAGScheduler: Broadcasting large task binary with size 1070.8 KiB\n",
      "22/12/13 00:41:42 WARN DAGScheduler: Broadcasting large task binary with size 1050.8 KiB\n",
      "22/12/13 00:41:45 WARN DAGScheduler: Broadcasting large task binary with size 1001.9 KiB\n",
      "22/12/13 00:41:49 WARN DAGScheduler: Broadcasting large task binary with size 1031.8 KiB\n",
      "22/12/13 00:41:52 WARN DAGScheduler: Broadcasting large task binary with size 1004.1 KiB\n",
      "22/12/13 00:41:56 WARN DAGScheduler: Broadcasting large task binary with size 1055.1 KiB\n",
      "22/12/13 00:41:59 WARN DAGScheduler: Broadcasting large task binary with size 1023.8 KiB\n",
      "22/12/13 00:42:03 WARN DAGScheduler: Broadcasting large task binary with size 1069.5 KiB\n",
      "22/12/13 00:42:06 WARN DAGScheduler: Broadcasting large task binary with size 1102.1 KiB\n",
      "22/12/13 00:42:10 WARN DAGScheduler: Broadcasting large task binary with size 1077.8 KiB\n",
      "22/12/13 00:42:14 WARN DAGScheduler: Broadcasting large task binary with size 1095.3 KiB\n",
      "22/12/13 00:42:17 WARN DAGScheduler: Broadcasting large task binary with size 1086.2 KiB\n",
      "22/12/13 00:42:21 WARN DAGScheduler: Broadcasting large task binary with size 1077.4 KiB\n",
      "22/12/13 00:42:24 WARN DAGScheduler: Broadcasting large task binary with size 1102.9 KiB\n",
      "22/12/13 00:42:28 WARN DAGScheduler: Broadcasting large task binary with size 1035.6 KiB\n",
      "22/12/13 00:42:31 WARN DAGScheduler: Broadcasting large task binary with size 1117.7 KiB\n",
      "22/12/13 00:42:35 WARN DAGScheduler: Broadcasting large task binary with size 1126.9 KiB\n",
      "22/12/13 00:42:39 WARN DAGScheduler: Broadcasting large task binary with size 1142.0 KiB\n",
      "22/12/13 00:42:42 WARN DAGScheduler: Broadcasting large task binary with size 1127.6 KiB\n",
      "22/12/13 00:42:46 WARN DAGScheduler: Broadcasting large task binary with size 1147.9 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 10536:>                                                      (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:42:50 WARN DAGScheduler: Broadcasting large task binary with size 1153.3 KiB\n",
      "22/12/13 00:42:54 WARN DAGScheduler: Broadcasting large task binary with size 1145.0 KiB\n",
      "22/12/13 00:42:57 WARN DAGScheduler: Broadcasting large task binary with size 1163.7 KiB\n",
      "22/12/13 00:43:01 WARN DAGScheduler: Broadcasting large task binary with size 1133.5 KiB\n",
      "22/12/13 00:43:05 WARN DAGScheduler: Broadcasting large task binary with size 1127.3 KiB\n",
      "22/12/13 00:43:09 WARN DAGScheduler: Broadcasting large task binary with size 1168.9 KiB\n",
      "22/12/13 00:43:12 WARN DAGScheduler: Broadcasting large task binary with size 1085.7 KiB\n",
      "22/12/13 00:43:16 WARN DAGScheduler: Broadcasting large task binary with size 1165.1 KiB\n",
      "22/12/13 00:43:20 WARN DAGScheduler: Broadcasting large task binary with size 1148.3 KiB\n",
      "22/12/13 00:43:23 WARN DAGScheduler: Broadcasting large task binary with size 1177.8 KiB\n",
      "22/12/13 00:43:27 WARN DAGScheduler: Broadcasting large task binary with size 1167.7 KiB\n",
      "22/12/13 00:43:31 WARN DAGScheduler: Broadcasting large task binary with size 1176.7 KiB\n",
      "22/12/13 00:43:34 WARN DAGScheduler: Broadcasting large task binary with size 1223.2 KiB\n",
      "22/12/13 00:43:38 WARN DAGScheduler: Broadcasting large task binary with size 1219.5 KiB\n",
      "22/12/13 00:43:42 WARN DAGScheduler: Broadcasting large task binary with size 1224.3 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 11406:>                                                      (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:43:46 WARN DAGScheduler: Broadcasting large task binary with size 1194.6 KiB\n",
      "22/12/13 00:43:50 WARN DAGScheduler: Broadcasting large task binary with size 1204.9 KiB\n",
      "22/12/13 00:43:54 WARN DAGScheduler: Broadcasting large task binary with size 1255.4 KiB\n",
      "22/12/13 00:43:58 WARN DAGScheduler: Broadcasting large task binary with size 1200.3 KiB\n",
      "22/12/13 00:44:02 WARN DAGScheduler: Broadcasting large task binary with size 1299.1 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 11696:>                                                      (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:44:06 WARN DAGScheduler: Broadcasting large task binary with size 1239.8 KiB\n",
      "22/12/13 00:44:10 WARN DAGScheduler: Broadcasting large task binary with size 1272.4 KiB\n",
      "22/12/13 00:44:13 WARN DAGScheduler: Broadcasting large task binary with size 1236.8 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 11870:>                                                      (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:44:17 WARN DAGScheduler: Broadcasting large task binary with size 1283.7 KiB\n",
      "22/12/13 00:44:21 WARN DAGScheduler: Broadcasting large task binary with size 1311.6 KiB\n",
      "22/12/13 00:44:25 WARN DAGScheduler: Broadcasting large task binary with size 1297.1 KiB\n",
      "22/12/13 00:44:29 WARN DAGScheduler: Broadcasting large task binary with size 1285.1 KiB\n",
      "22/12/13 00:44:33 WARN DAGScheduler: Broadcasting large task binary with size 1267.7 KiB\n",
      "22/12/13 00:44:37 WARN DAGScheduler: Broadcasting large task binary with size 1311.7 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 12218:>                                                      (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:44:41 WARN DAGScheduler: Broadcasting large task binary with size 1311.7 KiB\n",
      "22/12/13 00:44:45 WARN DAGScheduler: Broadcasting large task binary with size 1283.5 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 12334:>                                                      (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:44:49 WARN DAGScheduler: Broadcasting large task binary with size 1311.0 KiB\n",
      "22/12/13 00:44:53 WARN DAGScheduler: Broadcasting large task binary with size 1327.4 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 12450:>                                                      (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:44:57 WARN DAGScheduler: Broadcasting large task binary with size 1309.6 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 12508:>                                                      (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:45:01 WARN DAGScheduler: Broadcasting large task binary with size 1279.5 KiB\n",
      "22/12/13 00:45:05 WARN DAGScheduler: Broadcasting large task binary with size 1271.2 KiB\n",
      "22/12/13 00:45:09 WARN DAGScheduler: Broadcasting large task binary with size 1300.1 KiB\n",
      "22/12/13 00:45:13 WARN DAGScheduler: Broadcasting large task binary with size 1265.6 KiB\n",
      "22/12/13 00:45:17 WARN DAGScheduler: Broadcasting large task binary with size 1256.6 KiB\n",
      "22/12/13 00:45:21 WARN DAGScheduler: Broadcasting large task binary with size 1220.1 KiB\n",
      "22/12/13 00:45:24 WARN DAGScheduler: Broadcasting large task binary with size 1245.3 KiB\n",
      "22/12/13 00:45:28 WARN DAGScheduler: Broadcasting large task binary with size 1254.3 KiB\n",
      "22/12/13 00:45:32 WARN DAGScheduler: Broadcasting large task binary with size 1177.0 KiB\n",
      "22/12/13 00:45:36 WARN DAGScheduler: Broadcasting large task binary with size 1273.6 KiB\n",
      "22/12/13 00:45:39 WARN DAGScheduler: Broadcasting large task binary with size 1232.4 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 13146:>                                                      (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:45:44 WARN DAGScheduler: Broadcasting large task binary with size 1264.8 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 13204:>                                                      (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:45:47 WARN DAGScheduler: Broadcasting large task binary with size 1237.5 KiB\n",
      "22/12/13 00:45:51 WARN DAGScheduler: Broadcasting large task binary with size 1281.9 KiB\n",
      "22/12/13 00:45:55 WARN DAGScheduler: Broadcasting large task binary with size 1260.6 KiB\n",
      "22/12/13 00:45:59 WARN DAGScheduler: Broadcasting large task binary with size 1253.1 KiB\n",
      "22/12/13 00:46:03 WARN DAGScheduler: Broadcasting large task binary with size 1286.7 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 13494:>                                                      (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:46:07 WARN DAGScheduler: Broadcasting large task binary with size 1234.6 KiB\n",
      "22/12/13 00:46:11 WARN DAGScheduler: Broadcasting large task binary with size 1264.4 KiB\n",
      "22/12/13 00:46:14 WARN DAGScheduler: Broadcasting large task binary with size 1300.6 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 13668:>                                                      (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/13 00:46:18 WARN DAGScheduler: Broadcasting large task binary with size 1182.0 KiB\n",
      "22/12/13 00:46:22 WARN DAGScheduler: Broadcasting large task binary with size 1241.8 KiB\n",
      "22/12/13 00:46:26 WARN DAGScheduler: Broadcasting large task binary with size 1224.3 KiB\n",
      "22/12/13 00:46:30 WARN DAGScheduler: Broadcasting large task binary with size 1235.5 KiB\n",
      "22/12/13 00:46:34 WARN DAGScheduler: Broadcasting large task binary with size 1221.9 KiB\n",
      "22/12/13 00:46:37 WARN DAGScheduler: Broadcasting large task binary with size 1240.8 KiB\n",
      "22/12/13 00:46:41 WARN DAGScheduler: Broadcasting large task binary with size 1225.2 KiB\n",
      "22/12/13 00:46:45 WARN DAGScheduler: Broadcasting large task binary with size 1191.1 KiB\n",
      "22/12/13 00:46:49 WARN DAGScheduler: Broadcasting large task binary with size 1224.0 KiB\n",
      "22/12/13 00:46:53 WARN DAGScheduler: Broadcasting large task binary with size 1180.4 KiB\n",
      "22/12/13 00:46:56 WARN DAGScheduler: Broadcasting large task binary with size 1188.3 KiB\n",
      "22/12/13 00:47:00 WARN DAGScheduler: Broadcasting large task binary with size 1162.9 KiB\n",
      "22/12/13 00:47:04 WARN DAGScheduler: Broadcasting large task binary with size 1091.0 KiB\n",
      "22/12/13 00:47:07 WARN DAGScheduler: Broadcasting large task binary with size 1153.5 KiB\n",
      "22/12/13 00:47:11 WARN DAGScheduler: Broadcasting large task binary with size 1113.3 KiB\n",
      "22/12/13 00:47:15 WARN DAGScheduler: Broadcasting large task binary with size 1056.4 KiB\n",
      "22/12/13 00:47:18 WARN DAGScheduler: Broadcasting large task binary with size 1062.3 KiB\n",
      "22/12/13 00:47:22 WARN DAGScheduler: Broadcasting large task binary with size 1065.2 KiB\n",
      "22/12/13 00:47:25 WARN DAGScheduler: Broadcasting large task binary with size 1059.5 KiB\n",
      "22/12/13 00:47:29 WARN DAGScheduler: Broadcasting large task binary with size 1015.7 KiB\n",
      "22/12/13 00:47:32 WARN DAGScheduler: Broadcasting large task binary with size 1067.3 KiB\n",
      "22/12/13 00:47:36 WARN DAGScheduler: Broadcasting large task binary with size 1055.7 KiB\n",
      "22/12/13 00:47:39 WARN DAGScheduler: Broadcasting large task binary with size 1056.2 KiB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "\n",
    "# https://stackoverflow.com/questions/51390676/how-to-visualize-pyspark-mls-lda-or-other-clustering\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from pyspark import SparkConf, SparkContext,SQLContext\n",
    "from pyspark.sql import SparkSession, functions\n",
    "from pyspark.ml.feature import Word2Vec,CountVectorizer,Tokenizer, StopWordsRemover\n",
    "from pyspark.ml.clustering import LDA, LDAModel\n",
    "from pyspark.sql.functions import col, udf, countDistinct, regexp_replace\n",
    "from pyspark.sql.types import IntegerType,ArrayType,StringType\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import lit, expr\n",
    "import csv\n",
    "\n",
    "def ith_(v, i):\n",
    "    try:\n",
    "        return float(v[i])\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "spark = SparkSession \\\n",
    ".builder \\\n",
    ".appName(\"Python Spark SQL basic example\") \\\n",
    ".config(\"spark.some.config.option\", \"some-value\") \\\n",
    ".getOrCreate()\n",
    "\n",
    "months = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "#months = [\"December\"]\n",
    "years = [\"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\"]\n",
    "#years = [\"2010\"]\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        csv_path = \"/\" + year + \"/\" + month + \".csv\"\n",
    "        json_path = \"/\" + year + \"/\" + month + \".json\"\n",
    "        data_path = \"../data\" + csv_path # Data path for csv file\n",
    "        spark_df = spark.read.csv(data_path, inferSchema = True, header=True) # checking the csv file\n",
    "        spark_df = spark_df.withColumn('Title', regexp_replace('Title', '\"', ''))\n",
    "        spark_df = spark_df.withColumn('Title', regexp_replace('Title', '-', ''))\n",
    "        spark_df = spark_df.withColumn('Title', regexp_replace('Title', '\\.', ''))\n",
    "        spark_df = spark_df.withColumn('Title', regexp_replace('Title', ',', ''))\n",
    "        spark_df = spark_df.withColumn('Title', regexp_replace('Title', '\\?', ''))\n",
    "        spark_df = spark_df.withColumn('Title', regexp_replace('Title', '\\!', ''))\n",
    "        spark_df = spark_df.withColumn('Title', regexp_replace('Title', '\\/', ''))\n",
    "        spark_df = spark_df.withColumn('Title', regexp_replace('Title', '\\\\\\\\', ''))\n",
    "        spark_df = spark_df.withColumn('Title', regexp_replace('Title', \"'\", ''))\n",
    "        spark_df = spark_df.withColumn('Title', regexp_replace('Title', ':', ''))\n",
    "        # Topic Modelling on Title (Potentially do it on description if possible)\n",
    "        node = \"Title\"\n",
    "        # Get title data, filter out empty nodes\n",
    "        title_data = spark_df.select(node).filter(functions.col(node).isNotNull())\n",
    "\n",
    "        df2 = spark_df.select(countDistinct(\"Subreddit\"))\n",
    "        topic_num = df2.first()[0]\n",
    "\n",
    "        tokenizer = Tokenizer(inputCol=\"Title\", outputCol=\"words\")\n",
    "        tokenized = tokenizer.transform(spark_df)\n",
    "        \n",
    "        tokenized = tokenized.withColumn(\"words\", expr(\"filter(words, elem -> elem != '')\"))\n",
    "        \n",
    "        remover = StopWordsRemover(stopWords=stopwords.words('english'), inputCol=\"words\", outputCol=\"filtered\")\n",
    "        result = remover.transform(tokenized)\n",
    "        \n",
    "        # result.select(\"filtered\").show()\n",
    "\n",
    "        cv = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\")\n",
    "        cvModel = cv.fit(result)\n",
    "        cvResult = cvModel.transform(result)\n",
    "\n",
    "        lda = LDA(maxIter=20, k = 10)\n",
    "        ldaModel = lda.fit(cvResult)\n",
    "        transformed = ldaModel.transform(cvResult).select(\"topicDistribution\")\n",
    "        #transformed.show(truncate=False)\n",
    "\n",
    "        vocab = cvModel.vocabulary\n",
    "        topics = ldaModel.describeTopics()\n",
    "        topics_rdd = topics.rdd\n",
    "\n",
    "        topics_words = topics_rdd\\\n",
    "               .map(lambda row: row['termIndices'])\\\n",
    "               .map(lambda idx_list: [vocab[idx] for idx in idx_list])\\\n",
    "               .collect()\n",
    "        topic_weights = topics_rdd\\\n",
    "               .map(lambda row: row['termWeights'])\\\n",
    "               .collect()\n",
    "\n",
    "        file_path = \"../processed_data\" + csv_path\n",
    "        if not os.path.exists(\"../processed_data/\" + year):\n",
    "            os.makedirs(\"../processed_data/\" + year)\n",
    "        with open(file_path, 'w') as file:\n",
    "            header = [\"term\", \"probability\", \"topic\"]\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(header)\n",
    "            for idx, topic in enumerate(topics_words):\n",
    "                i = 0\n",
    "                for word in topic:\n",
    "                    data = [word, topic_weights[idx][i], idx]\n",
    "                    writer.writerow(data)\n",
    "                    i = i+1\n",
    "\n",
    "        json_df = pd.read_csv(file_path)\n",
    "        json_df.to_json(\"../processed_data\" + json_path, orient = \"table\")\n",
    "        \n",
    "        dist = ldaModel.transform(cvResult)\n",
    "\n",
    "        ith = udf(ith_, DoubleType())\n",
    "        df = dist.select([\"Title\"] + [ith(\"topicDistribution\", lit(i)).alias('topic_'+str(i)) for i in range(10)] )\n",
    "\n",
    "        df_p = dist.select('topicDistribution').toPandas()\n",
    "        df_p1 = df_p.topicDistribution.apply(lambda x:np.array(x))\n",
    "        df_p2 = pd.DataFrame(df_p1.tolist()).apply(lambda x:x.argmax(),axis=1)\n",
    "        df_p3 = df_p2.reset_index()\n",
    "        df_p3.columns = ['doc','topic']\n",
    "        df2_p = dist.select('Title').toPandas()\n",
    "        #print(df_p3)\n",
    "        final_df = pd.concat([df2_p, df_p3], axis=1)\n",
    "        topic_path = \"../document_topics\" + csv_path\n",
    "        if not os.path.exists(\"../document_topics/\" + year):\n",
    "            os.makedirs(\"../document_topics/\" + year)\n",
    "        final_df.to_csv(topic_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
