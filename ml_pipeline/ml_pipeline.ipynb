{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"name":"stdout","output_type":"stream","text":["+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n","|               Title|          Title Link|              Author|               Score|        Num Comments|           Subreddit|\n","+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n","|TIL the Vice Pres...|https://publicapo...|          douggold11|               22719|                1308|       todayilearned|\n","|What’s your toxic...|                 N/A|         KingOfLoser|               16369|               10396|           AskReddit|\n","|Herschel Walker v...|https://www.busin...|        Singing_Wolf|               13530|                1280|            politics|\n","|Qatari security t...|https://v.redd.it...|    Rollo_Tomasi3000|               85855|                4588|    nextfuckinglevel|\n","|North Carolina po...|https://v.redd.it...|        FarmSuch5021|               28059|                3603|         ThatsInsane|\n","|Boy who is deaf h...|https://v.redd.it...|              SGTC36|               14654|                 548|Damnthatsinteresting|\n","|Declining Global ...|https://weather.c...|             yourSAS|               14342|                3265|          Futurology|\n","|Title isn’t even ...|https://v.redd.it...|applesandshenanigans|               60286|                3131|        IdiotsInCars|\n","|Guy tries to catc...|https://v.redd.it...|          shamansufi|                8878|                 349|WatchPeopleDieInside|\n","|what's something ...|                 N/A|     -falafelwaffle-|                4594|                2948|              AskMen|\n","|Joe Biden, Olaf S...|https://i.redd.it...|Such-Acanthocephala1|               50937|                3050|              europe|\n","|N.Y. disbars lawy...|https://www.reute...|      Scalar_Mikeman|               32982|                2926|                news|\n","|Jon Stewart On Da...|https://www.youtu...|        optiplex9000|               15991|                2821|              videos|\n","|\"Kevin Durant: \"\"...|       Royce O’Neale|          Joe Harris| [Nic] Claxton an...| but what are you...|                 N/A|\n","|Qatari security t...|https://v.redd.it...|           mossadnik|               49854|                2615|   interestingasfuck|\n","|You were late... ...|https://v.redd.it...|            DnlNicks|               13427|                 315|    nextfuckinglevel|\n","|My local Microcen...|https://i.redd.it...|           Vatican87|               16946|                1797|        pcmasterrace|\n","|3.20 Balance Mani...|https://www.patho...|       FracturedRoah|                7873|                2588|         pathofexile|\n","|A woman named Elv...|https://i.redd.it...|      shelbykaramoko|               25201|                 592|  nevertellmetheodds|\n","|a jack of all trades|https://v.redd.it...|             Alodhri|               69547|                2438|               funny|\n","+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n","only showing top 20 rows\n","\n"]}],"source":["import os\n","import nltk\n","\n","# https://stackoverflow.com/questions/51390676/how-to-visualize-pyspark-mls-lda-or-other-clustering\n","\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","\n","from pyspark import SparkConf, SparkContext,SQLContext\n","from pyspark.sql import SparkSession, functions\n","from pyspark.ml.feature import Word2Vec,CountVectorizer,Tokenizer, StopWordsRemover\n","from pyspark.ml.clustering import LDA, LDAModel\n","from pyspark.sql.functions import col, udf\n","from pyspark.sql.types import IntegerType,ArrayType,StringType\n","\n","\n","spark = SparkSession \\\n",".builder \\\n",".appName(\"Python Spark SQL basic example\") \\\n",".config(\"spark.some.config.option\", \"some-value\") \\\n",".getOrCreate()\n","\n","data_path = \"gs://6893finalpruv/2.csv\" # Data path for csv file\n","spark_df = spark.read.csv(data_path, inferSchema = True, header=True) # checking the csv file\n","spark_df.show()\n","\n","# Topic Modelling on Title (Potentially do it on description if possible)\n","node = \"Title\"\n","# Get title data, filter out empty nodes\n","title_data = spark_df.select(node).filter(functions.col(node).isNotNull())"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["from pyspark.sql.functions import countDistinct\n","df2 = spark_df.select(countDistinct(\"Subreddit\"))\n","topics = df2.first()[0]"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+\n","|            filtered|\n","+--------------------+\n","|[til, vice, presi...|\n","|[what’s, toxic, t...|\n","|[herschel, walker...|\n","|[qatari, security...|\n","|[north, carolina,...|\n","|[boy, deaf, hears...|\n","|[declining, globa...|\n","|[title, isn’t, ev...|\n","|[guy, tries, catc...|\n","|[what's, somethin...|\n","|[joe, biden,, ola...|\n","|[n.y., disbars, l...|\n","|[jon, stewart, da...|\n","|[\"kevin, durant:,...|\n","|[qatari, security...|\n","|[late..., 60, yea...|\n","|[local, microcent...|\n","|[3.20, balance, m...|\n","|[woman, named, el...|\n","|      [jack, trades]|\n","+--------------------+\n","only showing top 20 rows\n","\n"]}],"source":["tokenizer = Tokenizer(inputCol=\"Title\", outputCol=\"words\")\n","tokenized = tokenizer.transform(spark_df)\n","remover = StopWordsRemover(stopWords=stopwords.words('english'), inputCol=\"words\", outputCol=\"filtered\")\n","result = remover.transform(tokenized)\n","result.select(\"filtered\").show()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["cv = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\")\n","cvModel = cv.fit(result)\n","cvResult = cvModel.transform(result)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|topicDistribution                                                                                                                                                                                                     |\n","+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|[0.007878400800887522,0.007830576177434635,0.00835470853177807,0.9298195113975268,0.007532009031698612,0.007857037848053503,0.007713179211811139,0.007599726548981892,0.0076548709978702155,0.007759979453957673]     |\n","|[0.013566497395055612,0.01348384518046326,0.8805761948502596,0.012961576850997636,0.012969623367257425,0.013530114912814868,0.013282158524058821,0.013086641583367914,0.013180958418365057,0.013362388917359682]      |\n","|[0.8949216781927232,0.01178336023941875,0.012573294643667184,0.011326686474111171,0.011333990428021865,0.011823211251647866,0.011606674320696298,0.011435553090971369,0.011518330091138274,0.011677221267604062]      |\n","|[0.008599210851469133,0.008546786602549424,0.009118847193834118,0.00821591385273388,0.008221113146493219,0.008575820094064192,0.9236024155616236,0.008295011494884439,0.008354953260048705,0.008469927942299222]      |\n","|[0.007878463403586226,0.00783047546762972,0.008355192061377543,0.007527282366635722,0.00753203001223503,0.007857040052344536,0.007713182129812818,0.007599774862168776,0.9299465224432931,0.007760037200916482]       |\n","|[0.011855046514713067,0.011783321696242709,0.012572335262748067,0.011326271196857465,0.011333388884389525,0.0118228979645638,0.011606130425718808,0.01143557598741782,0.8945885881898905,0.011676443877458283]        |\n","|[0.010527165845126153,0.010462767112594754,0.011165033406912796,0.010058532607800577,0.010063903529725346,0.906663902251481,0.010306830175924575,0.010154428423908747,0.010228135462651182,0.010369301183874944]      |\n","|[0.8594808484795395,0.01575733562399626,0.016812253038281693,0.015147292988533033,0.01515686362261573,0.015811194646672987,0.015521276415160318,0.015293095572808087,0.0154042028582365,0.015615636754155829]         |\n","|[0.01356509453185737,0.879683416156779,0.014386385239830556,0.012960566224345133,0.012968713696140072,0.013528335524640049,0.013280578256946928,0.013085303908351461,0.013180300388850685,0.013361306072258765]       |\n","|[0.015854178227008672,0.01575808312356505,0.016815815692522818,0.015147493196440315,0.015157100841992795,0.85943238544208,0.015521548399696864,0.01529354983408864,0.015403906393523127,0.015615938849081658]         |\n","|[0.0049645562338346445,0.004934292138540836,0.005264594952002172,0.004743242786029882,0.004746287478708891,0.9559842413801688,0.004860398328115513,0.0047889343376597724,0.004823535846928867,0.004889916518010651]   |\n","|[0.007879456656391665,0.007831182131019299,0.008356176368934164,0.0075278537843689024,0.00753245985253967,0.007857897174510816,0.007714001244860935,0.007600295547817437,0.9299399214545971,0.007760755784959982]     |\n","|[0.010526059475771262,0.010461958910397025,0.01116239501982146,0.010056872270187008,0.010063238918593542,0.9066754820868281,0.010305263457489377,0.010153690722582029,0.010227126478255256,0.01036791266007487]       |\n","|[0.011855191293074259,0.011782641201746855,0.012572581167133074,0.8943973051897232,0.011333524408739373,0.011822775636839384,0.01160608899341318,0.011435242563704437,0.01151811136096239,0.01167653818466382]        |\n","|[0.008599295425372966,0.008546784451435148,0.009118829920044423,0.008215910829111715,0.008221113067610005,0.0085758269855915,0.9236023704074727,0.008295001142292703,0.00835495745855454,0.008469910312514263]        |\n","|[0.019071647920552506,0.8308456719538904,0.020224187616435657,0.01822167297544021,0.018233156031115173,0.019019827547843666,0.018671609162619562,0.01839705126766903,0.018530234879510436,0.018784940644923174]       |\n","|[0.009466799881235454,0.009409435150901282,0.01003961046081303,0.009044377003821609,0.9156761539607011,0.009442070373808155,0.009268026819245684,0.009131671706658403,0.00919765562890675,0.00932419901390864]        |\n","|[0.879766221368039,0.01348274824503633,0.014385307767045257,0.012960700651205245,0.012968850986125538,0.013528533453363979,0.013280720881938438,0.013085404159822777,0.013179954891639485,0.013361557595784022]       |\n","|[0.003927206256884204,0.0039032640179431093,0.9654296757866809,0.003752100796858713,0.0037544912626278964,0.003916502066951404,0.0038447834100002807,0.0037882285352891162,0.0038156138968219347,0.003868133969942248]|\n","|[0.03210578594019446,0.031910240136189386,0.03404653896257293,0.03067441488319602,0.03069345743219452,0.03201817785039955,0.0314317285091733,0.714303344317697,0.031193574776556928,0.03162273719182581]              |\n","+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","only showing top 20 rows\n","\n"]}],"source":["lda = LDA(maxIter=20, k = 10)\n","ldaModel = lda.fit(cvResult)\n","transformed = ldaModel.transform(cvResult).select(\"topicDistribution\")\n","transformed.show(truncate=False)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ll:  -49528.10066245525\n","lp:  14.318618289232509\n"]}],"source":["ll = ldaModel.logLikelihood(cvResult)\n","lp = ldaModel.logPerplexity(cvResult)\n","print(\"ll: \", ll)\n","print(\"lp: \", lp)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["topic: 0\n","*************************\n","finished\n","musk\n","%\n","vs\n","two\n","long\n","round\n","next\n","trump's\n","took\n","*************************\n","topic: 1\n","*************************\n","i’m\n","one\n","years\n","game\n","every\n","late.\n","make\n","promoting\n","away\n","8\n","*************************\n","topic: 2\n","*************************\n","like\n","new\n","possible\n","office\n","take\n","really\n","getting\n","released\n","ice\n","close\n","*************************\n","topic: 3\n","*************************\n","shooting\n","states\n","united\n","gemma\n",",\n","memorial\n","3\n","band\n","making\n","map\n","*************************\n","topic: 4\n","*************************\n","nnn\n","it’s\n","horny\n","participant\n","low\n","least\n","pay\n","beats\n","willingness\n","food,\n","*************************\n","topic: 5\n","*************************\n","it’s\n","would\n","cell\n","taking\n","cat\n","body\n","this?\n","brain\n","party\n","this.\n","*************************\n","topic: 6\n","*************************\n","world\n","cup\n","disrespectful\n","report\n","made\n","likely\n","longer\n","camera\n","tv\n","qatari\n","*************************\n","topic: 7\n","*************************\n","question\n","home\n","mom\n","try\n","8-year-old\n","half\n","mile\n","son\n","making\n","jailed\n","*************************\n","topic: 8\n","*************************\n","people\n","get\n","still\n","high\n","car\n","mental\n","many\n","year\n","health\n","thalmor\n","*************************\n","topic: 9\n","*************************\n","buddy\n","next\n","good\n","floridaman\n","arrested\n","sex\n","mass.\n","15-year\n","naming\n","manhunt\n","*************************\n"]}],"source":["vocab = cvModel.vocabulary\n","topics = ldaModel.describeTopics()\n","topics_rdd = topics.rdd\n","\n","topics_words = topics_rdd\\\n","       .map(lambda row: row['termIndices'])\\\n","       .map(lambda idx_list: [vocab[idx] for idx in idx_list])\\\n","       .collect()\n","for idx, topic in enumerate(topics_words):\n","    print(\"topic: {}\".format(idx))\n","    print(\"*\"*25)\n","    for word in topic:\n","       print(word)\n","    print(\"*\"*25)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":2}