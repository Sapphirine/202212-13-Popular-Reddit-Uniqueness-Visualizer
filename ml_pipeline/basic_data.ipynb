{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97754e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/alirahman/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "\n",
    "# https://stackoverflow.com/questions/51390676/how-to-visualize-pyspark-mls-lda-or-other-clustering\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from pyspark import SparkConf, SparkContext,SQLContext\n",
    "from pyspark.sql import SparkSession, functions\n",
    "from pyspark.ml.feature import Word2Vec,CountVectorizer,Tokenizer, StopWordsRemover\n",
    "from pyspark.ml.clustering import LDA, LDAModel\n",
    "from pyspark.sql.functions import col, udf, countDistinct, regexp_replace\n",
    "from pyspark.sql.types import IntegerType,ArrayType,StringType\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import lit\n",
    "import csv\n",
    "\n",
    "def ith_(v, i):\n",
    "    try:\n",
    "        return float(v[i])\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "spark = SparkSession \\\n",
    ".builder \\\n",
    ".appName(\"Python Spark SQL basic example\") \\\n",
    ".config(\"spark.some.config.option\", \"some-value\") \\\n",
    ".getOrCreate()\n",
    "\n",
    "months = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "#months = [\"January\"]\n",
    "years = [\"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\"]\n",
    "#years = [\"2010\"]\n",
    "#lookup = {\"January\": \"01\", \"February\":\"02\", \"March\":\"03\", \"April\":\"04\", \"May\":\"05\", \"June\": \"06\", \"July\":\"07\", \"August\":\"08\", \"September\":\"09\", \"October\":\"10\", \"November\":\"11\", \"December\":\"12\"}\n",
    "with open(\"../processed_data/lines/data.csv\", 'w') as file:\n",
    "    header = [\"date\", \"score\", \"comments\", \"num_posts\"]\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "    for year in years:\n",
    "        for month in months:\n",
    "            csv_path = \"/\" + year + \"/\" + month + \".csv\"\n",
    "            json_path = \"/\" + year + \"/\" + month + \".json\"\n",
    "            data_path = \"../data\" + csv_path # Data path for csv file\n",
    "            spark_df = spark.read.csv(data_path, inferSchema = True, header=True) # checking the csv file\n",
    "            score = int(spark_df.agg({'Score': 'sum'}).first()[0])\n",
    "            com = int(spark_df.agg({'Num Comments': 'sum'}).first()[0])\n",
    "            data = [year + \"-\" + lookup[month], score, com, spark_df.count()]\n",
    "            writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11d3b00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
